### 高并发与多线程
>
- 高并发与编程语言无关，多线程与编程语言相关。
>
- 高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求。
>
- 高并发相关常用的一些指标有响应时间（Response Time），吞吐量（Throughput），每秒查询率QPS（Query Per Second），并发用户数等。
>
- 响应时间：系统对请求做出响应的时间。例如系统处理一个HTTP请求需要200ms，这个200ms就是系统的响应时间。
- 吞吐量：单位时间内处理的请求数量。
- QPS：每秒响应请求数。在互联网领域，这个指标和吞吐量区分的没有这么明显。
- 并发用户数：同时承载正常使用系统功能的用户数量。例如一个即时通讯系统，同时在线量一定程度上代表了系统的并发用户数。
>
- 高并发是针对高访问量，应对高访问量，增加服务器性能。提高并发能力，垂直扩展于水平扩展。
>
- 垂直扩展：提升单机处理能力。垂直扩展的方式又有两种：
>
- （1）增强单机硬件性能（硬件工程师），例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G；
>
- （2）提升单机架构性能（软件工程师），例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间； 
>
- 不管是提升单机硬件性能，还是提升单机架构性能，都有一个致命的不足：**单机性能总是有极限的**。所以互联网分布式架构设计高并发终极解决方案还是水平扩展。
>
- 水平扩展：只要增加服务器数量，就能线性扩充系统性能。水平扩展对系统架构设计是有要求的，如何在架构各层进行可水平扩展的设计，以及互联网公司架构各层常见的水平扩展实践，.
>
### 常见的互联网分层架构
>
![](https://github.com/lu666666/notebooks/blob/master/java/0/3/pic/10.png)
>
- 常见互联网分布式架构如上，分为：
>
- （1）客户端层：典型调用方是浏览器browser或者手机应用APP
>
- （2）反向代理层：系统入口，反向代理
>
- （3）站点应用层：实现核心应用逻辑，返回html或者json
>
- （4）服务层：如果实现了服务化，就有这一层
>
- （5）数据-缓存层：缓存加速访问存储
>
- （6）数据-数据库层：数据库固化数据存储
>
- 整个系统各层次的水平扩展，又分别是如何实施的呢？
>
### 分层水平扩展架构实践
>
#### 反向代理层的水平扩展
>
![](https://github.com/lu666666/notebooks/blob/master/java/0/3/pic/11.png)
>
- 反向代理层的水平扩展，是通过“DNS轮询”实现的：dns-server对于一个域名配置了多个解析ip，每次DNS解析请求来访问dns-server，会轮询返回这些ip。
>
- 当nginx成为瓶颈的时候，只要增加服务器数量，新增nginx服务的部署，增加一个外网ip，就能扩展反向代理层的性能，做到理论上的无限高并发。
>
#### 站点层的水平扩展
>
![](https://github.com/lu666666/notebooks/blob/master/java/0/3/pic/12.png)
>
- 站点层的水平扩展，是通过“nginx”实现的。通过修改nginx.conf，可以设置多个web后端。
>
- 当web后端成为瓶颈的时候，只要增加服务器数量，新增web服务的部署，在nginx配置中配置上新的web后端，就能扩展站点层的性能，做到理论上的无限高并发。
>
#### 服务层的水平扩展
>
![](https://github.com/lu666666/notebooks/blob/master/java/0/3/pic/13.png)
>
- 服务层的水平扩展，是通过“服务连接池”实现的。
>
- 站点层通过RPC-client调用下游的服务层RPC-server时，RPC-client中的连接池会建立与下游服务多个连接，当服务成为瓶颈的时候，只要增加服务器数量，新增服务部署，在RPC-client处建立新的下游服务连接，就能扩展服务层性能，做到理论上的无限高并发。
- 如果需要优雅的进行服务层自动扩容，这里可能需要配置中心里服务自动发现功能的支持。
>
### 数据层的水平扩展
>
- 在数据量很大的情况下，数据层（缓存，数据库）涉及数据的水平扩展，将原本存储在一台服务器上的数据（缓存，数据库）水平拆分到不同服务器上去，以达到扩充系统性能的目的。
>
- 互联网数据层常见的水平拆分方式有这么几种，以数据库为例：
>
#### 按照范围水平拆分
>
![](https://github.com/lu666666/notebooks/blob/master/java/0/3/pic/14.png)
>
- 每一个数据服务，存储一定范围的数据，上图为例：
>
- user0库，存储uid范围1-1kw
>
- user1库，存储uid范围1kw-2kw
>
- 这个方案的好处是：
>
- （1）规则简单，service只需判断一下uid范围就能路由到对应的存储服务；
>
- （2）数据均衡性较好；
>
- （3）比较容易扩展，可以随时加一个uid[2kw,3kw]的数据服务；
>
- 不足是：

- （1）请求的负载不一定均衡，一般来说，新注册的用户会比老用户更活跃，大range的服务请求压力会更大；
>
#### 按照哈希水平拆分
>
![](https://github.com/lu666666/notebooks/blob/master/java/0/3/pic/15.png)
>
- 每一个数据库，存储某个key值hash后的部分数据，上图为例：
>
- user0库，存储偶数uid数据
>
- user1库，存储奇数uid数据
>
- 这个方案的好处是：
>
- （1）规则简单，service只需对uid进行hash能路由到对应的存储服务；
>
- （2）数据均衡性较好；
>
- （3）请求均匀性较好；
>
- 不足是：
>
- （1）不容易扩展，扩展一个数据服务，hash方法改变时候，可能需要进行数据迁移；
>
- 这里需要注意的是，通过水平拆分来扩充系统性能，与主从同步读写分离来扩充数据库性能的方式有本质的不同。
>
#### 通过水平拆分扩展数据库性能：
>
- （1）每个服务器上存储的数据量是总量的1/n，所以单机的性能也会有提升；
>
- （2）n个服务器上的数据没有交集，那个服务器上数据的并集是数据的全集；
>
- （3）数据水平拆分到了n个服务器上，理论上读性能扩充了n倍，写性能也扩充了n倍（其实远不止n倍，因为单机的数据量变为了原来的1/n）；
>
#### 通过主从同步读写分离扩展数据库性能：
>
- （1）每个服务器上存储的数据量是和总量相同；
>
- （2）n个服务器上的数据都一样，都是全集；
>
- （3）理论上读性能扩充了n倍，写仍然是单点，写性能不变；
>
- 缓存层的水平拆分和数据库层的水平拆分类似，也是以范围拆分和哈希拆分的方式居多，就不再展开。
>
### 总结
>
- 高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求。
>
- 提高系统并发能力的方式，方法论上主要有两种：垂直扩展（Scale Up）与水平扩展（Scale Out）。前者垂直扩展可以通过提升单机硬件性能，或者提升单机架构性能，来提高并发性，但单机性能总是有极限的，互联网分布式架构设计高并发终极解决方案还是后者：水平扩展。
>
- 互联网分层架构中，各层次水平扩展的实践又有所不同：
>
- （1）反向代理层可以通过“DNS轮询”的方式来进行水平扩展；
>
- （2）站点层可以通过nginx来进行水平扩展；
>
- （3）服务层可以通过服务连接池来进行水平扩展；
>
- （4）数据库可以按照数据范围，或者数据哈希的方式来进行水平扩展；
>
- 各层实施水平扩展后，能够通过增加服务器数量的方式来提升系统的性能，做到理论上的性能无限。
>
### Java处理高并发量访问的处理
>
#### 1、HTML静态化
>
- 效率最高、消耗最小的就是纯静态化的html页面，所以我们尽可能使我们的网站上的页面采用静态页面来实现，这个最简单的方法其实也是最有效的方法。但是对于大量内容并且频繁更新的网站，我们无法全部手动去挨个实现，于是出现了我们常见的**信息发布系统CMS**，像我们常访问的各个门户站点的新闻频道，甚至他们的其他频道，都是通过信息发布系统来管理和实现的，**信息发布系统可以实现最简单的信息录入自动生成静态页面，还能具备频道管理、权限管理、自动抓取等功能**，对于一个大型网站来说，拥有一套高效、可管理的CMS是必不可少的。
>
- 除了门户和信息发布类型的网站，对于交互性要求很高的社区类型网站来说，尽可能的静态化也是提高性能的必要手段，将社区内的帖子、文章**进行实时的静态化、有更新的时候再重新静态化**也是大量使用的策略，像Mop的大杂烩就是使用了这样的策略，网易社区等也是如此。
>
- 同时，**html静态化也是某些缓存策略使用的手段，对于系统中频繁使用数据库查询但是内容更新很小的应用，可以考虑使用html静态化来实现**。比如论坛中论坛的公用设置信息，这些信息目前的主流论坛都可以进行后台管理并且存储在数据库中，这些信息其实大量被前台程序调用，但是更新频率很小，可以考虑将这部分内容进行后台更新的时候进行静态化，这样避免了大量的数据库访问请求。
>
#### 2、图片服务器分离
>
- 对于Web服务器来说，不管是Apache、IIS还是其他容器，图片是最消耗资源的，于是我们有必要将图片与页面进行分离，这是基本上大型网站都会采用的策略，他们都有**独立的、甚至很多台的图片服务器**。这样的架构可以**降低提供页面访问请求的服务器系统压力，并且可以保证系统不会因为图片问题而崩溃**。
>
- 在应用服务器和图片服务器上，可以进行不同的配置优化，比如apache在配置ContentType的时候可以尽量少支持、尽可能少的LoadModule，保证更高的系统消耗和执行效率。
>
#### 3、数据库集群、库表散列
>
- 大型网站都有复杂的应用，这些应用必须使用数据库，那么在面对大量访问的时候，数据库的瓶颈很快就能显现出来，这时一台数据库将很快无法满足应用，于是我们需要使用数据库集群或者库表散列。
>
- 在数据库集群方面，很多数据库都有自己的解决方案，Oracle、Sybase等都有很好的方案，常用的**MySQL提供的Master/Slave**也是类似的方案，您使用了什么样的DB，就参考相应的解决方案来实施即可。
>
- 上面提到的数据库集群由于在架构、成本、扩张性方面都会受到所采用DB类型的限制，于是我们需要**从应用程序的角度**来考虑改善系统架构，**库表散列**是常用并且最有效的解决方案。
>
- 我们在应用程序中安装业务和应用或者功能模块将数据库进行分离，**不同的模块对应不同的数据库或者表，再按照一定的策略对某个页面或者功能进行更小的数据库散列，**比如用户表，按照用户ID进行表散列，这样就能够低成本的提升系统的性能并且有很好的扩展性。
>
- sohu的论坛就是采用了这样的架构，将论坛的用户、设置、帖子等信息进行数据库分离，然后对帖子、用户按照板块和ID进行散列数据库和表，最终可以在配置文件中进行简单的配置便能让系统随时增加一台低成本的数据库进来补充系统性能。
>
#### 4、缓存（高速访问的中间件）
>
- 缓存一词搞技术的都接触过，很多地方用到缓存。网站架构和网站开发中的缓存也是非常重要。这里先讲述最基本的两种缓存。高级和分布式的缓存在后面讲述。
>
- 架构方面的缓存，对Apache比较熟悉的人都能知道Apache提供了自己的缓存模块，也可以使用外加的Squid模块进行缓存，这两种方式均可以有效的提高Apache的访问响应能力。
>
- 网站程序开发方面的缓存，Linux上提供的**Memory Cache是常用的缓存接口**，可以在web开发中使用，比如用Java开发的时候就可以调用MemoryCache对一些数据进行缓存和通讯共享，一些大型社区使用了这样的架构。另外，在使用web语言开发的时候，各种语言基本都有自己的缓存模块和方法，PHP有Pear的Cache模块，Java就更多了，.net不是很熟悉，相信也肯定有。
>
#### 5、镜像
>
- 镜像是大型网站常采用的提高性能和数据安全性的方式，镜像的技术可以解决不同网络接入商和地域带来的用户访问速度差异，比如ChinaNet和EduNet之间的差异就促使了很多网站在教育网内搭建镜像站点，数据进行定时更新或者实时更新。在镜像的细节技术方面，这里不阐述太深，有很多专业的现成的解决架构和产品可选。也有廉价的通过软件实现的思路，比如linux上的rsync等工具。
>
#### 6、负载均衡
>
- 负载均衡将是大型网站解决高负荷访问和大量并发请求采用的高端解决办法。
>
- 负载均衡技术发展了多年，有很多专业的服务提供商和产品可以选择，我个人接触过一些解决方法，其中有两个架构可以给大家做参考。
>
- （1）、**硬件四层交换**
>
- 第四层交换使用第三层和第四层信息包的报头信息，根据应用区间识别业务流，将整个区间段的业务流分配到合适的应用服务器进行处理。
>
- 第四层交换功能就像是虚IP，指向物理服务器。它传输的业务服从的协议多种多样，有HTTP、FTP、NFS、Telnet或其他协议。这些业务在物理服务器基础上，需要复杂的载量平衡算法。在IP世界，业务类型由终端TCP或UDP端口地址来决定，在第四层交换中的应用区间则由源端和终端IP地址、TCP和UDP端口共同决定。
>
- 在硬件四层交换产品领域，有一些知名的产品可以选择，比如Alteon、F5等，这些产品很昂贵，但是物有所值，能够提供非常优秀的性能和很灵活的管理能力。“Yahoo中国”当初接近2000台服务器，只使用了三、四台Alteon就搞定了。
>
- (2)、**软件四层交换**
>
- 大家知道了硬件四层交换机的原理后，基于OSI模型来实现的软件四层交换也就应运而生，这样的解决方案实现的原理一致，不过性能稍差。但是满足一定量的压力还是游刃有余的，有人说软件实现方式其实更灵活，处理能力完全看你配置的熟悉能力。
>
- 软件四层交换我们可以使用Linux上常用的LVS来解决，LVS就是Linux Virtual Server，他提供了基于心跳线heartbeat的实时灾难应对解决方案，提高系统的强壮性，同时可供了灵活的虚拟VIP配置和管理功能，可以同时满足多种应用需求，这对于分布式的系统来说必不可少。
>
- 一个典型的使用负载均衡的策略就是，在软件或者硬件四层交换的基础上搭建squid集群，这种思路在很多大型网站包括搜索引擎上被采用，这样的架构低成本、高性能还有很强的扩张性，随时往架构里面增减节点都非常容易。
>
- 对于大型网站来说，前面提到的每个方法可能都会被同时使用到，这里介绍得比较浅显，具体实现过程中很多细节还需要大家慢慢熟悉和体会。有时一个很小的squid参数或者apache参数设置，对于系统性能的影响就会很大。
>
#### 7、最新：CDN加速技术
>
- 什么是CDN？
>
- CDN的全称是内容分发网络。其目的是通过在现有的Internet中增加一层新的网络架构，将网站的内容发布到最接近用户的网络“边缘”，使用户可以就近取得所需的内容，提高用户访问网站的响应速度。
>
- CDN有别于镜像，因为它比镜像更智能，或者可以做这样一个比喻：CDN=更智能的镜像+缓存+流量导流。因而，CDN可以明显提高Internet网络中信息流动的效率。从技术上全面解决由于网络带宽小、用户访问量大、网点分布不均等问题，提高用户访问网站的响应速度。
>
- **CDN的类型特点**
>
- CDN的实现分为三类：镜像、高速缓存、专线。
>
- 镜像站点（Mirror Site），是最常见的，它让内容直接发布，适用于静态和准动态的数据同步。但是购买和维护新服务器的费用较高，还必须在各个地区设置镜像服务器，配备专业技术人员进行管理与维护。对于大型网站来说，更新所用的带宽成本也大大提高了。
>
- 高速缓存，成本较低，适用于静态内容。Internet的统计表明，超过80%的用户经常访问的是20%的网站的内容，在这个规律下，缓存服务器可以处理大部分客户的静态请求，而原始的服务器只需处理约20%左右的非缓存请求和动态请求，于是大大加快了客户请求的响应时间，并降低了原始服务器的负载。
>
- CDN服务一般会在全国范围内的关键节点上放置缓存服务器。
>
- 专线，让用户直接访问数据源，可以实现数据的动态同步。
>
- **CDN的实例**
>
- 举个例子来说，当某用户访问网站时，网站会利用全球负载均衡技术，将用户的访问指向到距离用户最近的正常工作的缓存服务器上，直接响应用户的请求。
>
- 当用户访问已经使用了CDN服务的网站时，其解析过程与传统解析方式的最大区别就在于网站的授权域名服务器不是以传统的轮询方式来响应本地DNS的解析请求，而是充分考虑用户发起请求的地点和当时网络的情况，来决定把用户的请求定向到离用户最近同时负载相对较轻的节点缓存服务器上。
>
- 通过用户定位算法和服务器健康检测算法综合后的数据，可以将用户的请求就近定向到分布在网络“边缘”的缓存服务器上，保证用户的访问能得到更及时可靠的响应。
>
- 由于大量的用户访问都由分布在网络边缘的CDN节点缓存服务器直接响应了，这就不仅提高了用户的访问质量，同时有效地降低了源服务器的负载压力。
>
- **附：某CDN服务商的服务说明**
>
- **采用GCDN加速方式**
>
- 采用了GCDN加速方式以后，系统会在浏览用户和您的服务器之间增加一台GCDN服务器。浏览用户访问您的服务器时，一般静态数据，如图片、多媒体资料等数据将直接从GCDN服务器读取，使得从主服务器上读取静态数据的交换量大大减少。
>
- 为VIP型虚拟主机而特加的VPN高速压缩通道，使用高速压缩的电信<==>网通、电信<==>国际（HK）、网通&lt;==>国际（HK）等跨网专线通道，智能多线，自动获取最快路径，极速的动态实时并发响应速度，实现了网站的动态脚本实时同步，对动态网站有一个更加明显的加速效果。
>




